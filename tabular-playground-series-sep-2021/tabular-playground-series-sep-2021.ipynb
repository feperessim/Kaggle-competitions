{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-04T15:41:48.417716Z","iopub.execute_input":"2021-09-04T15:41:48.419192Z","iopub.status.idle":"2021-09-04T15:41:48.455978Z","shell.execute_reply.started":"2021-09-04T15:41:48.41905Z","shell.execute_reply":"2021-09-04T15:41:48.454748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split, KFold, GridSearchCV\nfrom sklearn.metrics import accuracy_score, roc_auc_score\n\nfrom xgboost import XGBClassifier","metadata":{"execution":{"iopub.status.busy":"2021-09-04T15:41:58.254379Z","iopub.execute_input":"2021-09-04T15:41:58.254775Z","iopub.status.idle":"2021-09-04T15:41:59.787745Z","shell.execute_reply.started":"2021-09-04T15:41:58.254738Z","shell.execute_reply":"2021-09-04T15:41:59.786433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-09-04T18:34:08.078362Z","iopub.execute_input":"2021-09-04T18:34:08.078846Z","iopub.status.idle":"2021-09-04T18:34:08.084457Z","shell.execute_reply.started":"2021-09-04T18:34:08.078795Z","shell.execute_reply":"2021-09-04T18:34:08.083072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train =  pd.read_csv('/kaggle/input/tabular-playground-series-sep-2021/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-04T15:41:59.789866Z","iopub.execute_input":"2021-09-04T15:41:59.790298Z","iopub.status.idle":"2021-09-04T15:42:29.171032Z","shell.execute_reply.started":"2021-09-04T15:41:59.790247Z","shell.execute_reply":"2021-09-04T15:42:29.169817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analyses - EDA\n\nAt first, lets do some EDA to get more acquainted with the dataset","metadata":{}},{"cell_type":"markdown","source":"Lets get some basic information about the dataset.\n\n1 - Look at some samples with head function;\n\n2 - Check how much rows does it has and also the data type of each of them;\n\n3 - Look at some central tendency metrics.","metadata":{}},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T17:23:31.651122Z","iopub.execute_input":"2021-09-03T17:23:31.65153Z","iopub.status.idle":"2021-09-03T17:23:31.697377Z","shell.execute_reply.started":"2021-09-03T17:23:31.651485Z","shell.execute_reply":"2021-09-03T17:23:31.696338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T17:23:31.698927Z","iopub.execute_input":"2021-09-03T17:23:31.69933Z","iopub.status.idle":"2021-09-03T17:23:31.724233Z","shell.execute_reply.started":"2021-09-03T17:23:31.69929Z","shell.execute_reply":"2021-09-03T17:23:31.722736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Dataset shape: ', df_train.shape )","metadata":{"execution":{"iopub.status.busy":"2021-09-03T17:23:31.72606Z","iopub.execute_input":"2021-09-03T17:23:31.726417Z","iopub.status.idle":"2021-09-03T17:23:31.734661Z","shell.execute_reply.started":"2021-09-03T17:23:31.726386Z","shell.execute_reply":"2021-09-03T17:23:31.73376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.describe()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T17:23:31.73791Z","iopub.execute_input":"2021-09-03T17:23:31.738209Z","iopub.status.idle":"2021-09-03T17:23:36.559404Z","shell.execute_reply.started":"2021-09-03T17:23:31.738182Z","shell.execute_reply":"2021-09-03T17:23:36.558428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets do some statistics on missing values","metadata":{}},{"cell_type":"code","source":"df_train.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T17:23:36.561452Z","iopub.execute_input":"2021-09-03T17:23:36.561866Z","iopub.status.idle":"2021-09-03T17:23:36.78184Z","shell.execute_reply.started":"2021-09-03T17:23:36.561823Z","shell.execute_reply":"2021-09-03T17:23:36.780813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"miss_perc = df_train.isnull().sum()/df_train.shape[0] * 100\nmiss_perc = miss_perc.sort_values(ascending=False)\nplt.rc('font', family='serif', size=16)\nplt.figure(figsize=(15,35))\nplt.title('Percentage of missing values on each variable')\nplt.xlabel('Percentage (%)')\nplt.ylabel('Feature')\nplt.barh(miss_perc.index, miss_perc.round(2), alpha=0.5)\n\n# for column in df_train.columns :\n#   print(column + ' ' + '%.2f' % miss_perc[column] + '%')","metadata":{"execution":{"iopub.status.busy":"2021-09-03T17:23:36.783123Z","iopub.execute_input":"2021-09-03T17:23:36.783403Z","iopub.status.idle":"2021-09-03T17:23:39.040476Z","shell.execute_reply.started":"2021-09-03T17:23:36.783376Z","shell.execute_reply":"2021-09-03T17:23:39.03966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As can be seen, all featuares have almost the same quantity of missing values. The maximum percentage of missing values does not surpass the 1.6% of the overall data available. Given the quiantity of data available, during the modeling, we will stick with the strategy of drop the rows with missing values, however we will also impute with mean value as a baseline.","metadata":{}},{"cell_type":"markdown","source":"Now lets verify how is the target variable distributed","metadata":{}},{"cell_type":"code","source":"# plt.figure(figsize=(6,4))\n# plt.hist(df_train['claim'], bins=2, color='#3498db', histtype='bar', edgecolor='white') \nsns.countplot(df_train['claim'])\nplt.title('Distribution of classes in target variable (claim) \\n')\nplt.xlabel('Claim')\nplt.ylabel('Count')","metadata":{"execution":{"iopub.status.busy":"2021-09-03T17:23:39.041712Z","iopub.execute_input":"2021-09-03T17:23:39.042206Z","iopub.status.idle":"2021-09-03T17:23:39.248612Z","shell.execute_reply.started":"2021-09-03T17:23:39.042174Z","shell.execute_reply":"2021-09-03T17:23:39.247938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, they are equally distributed, thus we won't need to do any kind of special treatment to deal with imbalance.","metadata":{}},{"cell_type":"markdown","source":"# Feature Selection\n\nSince we have a lot of features, it will be too much work to analyse one of them at once alone. Thus, lets use some method to help analysing those features that are most important to our analyses.","metadata":{}},{"cell_type":"markdown","source":"# Mutual Information","metadata":{}},{"cell_type":"code","source":"x = df_train.copy().drop('id', axis=1)\nx.dropna(inplace=True)\ny = x.pop('claim')","metadata":{"execution":{"iopub.status.busy":"2021-09-04T19:16:11.846314Z","iopub.execute_input":"2021-09-04T19:16:11.846734Z","iopub.status.idle":"2021-09-04T19:16:13.214242Z","shell.execute_reply.started":"2021-09-04T19:16:11.846702Z","shell.execute_reply":"2021-09-04T19:16:13.213196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discrete_features = x.dtypes == int","metadata":{"execution":{"iopub.status.busy":"2021-09-04T19:16:13.216082Z","iopub.execute_input":"2021-09-04T19:16:13.216472Z","iopub.status.idle":"2021-09-04T19:16:13.223164Z","shell.execute_reply.started":"2021-09-04T19:16:13.21643Z","shell.execute_reply":"2021-09-04T19:16:13.221881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_mi_scores(x, y, discrete_features):\n    mi_scores = mutual_info_classif(x, y, discrete_features=discrete_features)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=x.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores","metadata":{"execution":{"iopub.status.busy":"2021-09-04T19:16:13.225496Z","iopub.execute_input":"2021-09-04T19:16:13.226361Z","iopub.status.idle":"2021-09-04T19:16:13.234928Z","shell.execute_reply.started":"2021-09-04T19:16:13.226318Z","shell.execute_reply":"2021-09-04T19:16:13.233914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_mi_scores(scores):\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks = list(scores.index)\n    plt.barh(width, scores)\n    plt.yticks(width, ticks)\n    plt.title(\"Mutual Information Scores\")","metadata":{"execution":{"iopub.status.busy":"2021-09-04T19:16:17.890596Z","iopub.execute_input":"2021-09-04T19:16:17.895204Z","iopub.status.idle":"2021-09-04T19:16:17.904633Z","shell.execute_reply.started":"2021-09-04T19:16:17.895155Z","shell.execute_reply":"2021-09-04T19:16:17.903198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mi_scores = make_mi_scores(x, y, discrete_features)\nmi_scores[::3]  # show a few features with their MI scores","metadata":{"execution":{"iopub.status.busy":"2021-09-04T19:16:20.208235Z","iopub.execute_input":"2021-09-04T19:16:20.208635Z","iopub.status.idle":"2021-09-04T19:28:45.260227Z","shell.execute_reply.started":"2021-09-04T19:16:20.208604Z","shell.execute_reply":"2021-09-04T19:28:45.258829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(dpi=100, figsize=(15, 35))\nplot_mi_scores(mi_scores)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T17:36:02.173297Z","iopub.execute_input":"2021-09-03T17:36:02.173721Z","iopub.status.idle":"2021-09-03T17:36:04.153243Z","shell.execute_reply.started":"2021-09-03T17:36:02.173648Z","shell.execute_reply":"2021-09-03T17:36:04.152257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('There are ', (mi_scores == 0).value_counts()[True], ' features with 0 score out of 118 features.')","metadata":{"execution":{"iopub.status.busy":"2021-09-03T17:36:04.154926Z","iopub.execute_input":"2021-09-03T17:36:04.155226Z","iopub.status.idle":"2021-09-03T17:36:04.164471Z","shell.execute_reply.started":"2021-09-03T17:36:04.155197Z","shell.execute_reply":"2021-09-03T17:36:04.163473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_metrics(model, x, y):\n    y_pred = model.predict(x)\n    acc = accuracy_score(y, y_pred)\n    y_pred_prob = model.predict_proba(x)[:, 1]\n    auc_roc = roc_auc_score(y, y_pred_prob)\n    return {'accuracy' : acc, 'auc_roc_curve' : auc_roc}","metadata":{"execution":{"iopub.status.busy":"2021-09-04T15:42:29.173208Z","iopub.execute_input":"2021-09-04T15:42:29.173649Z","iopub.status.idle":"2021-09-04T15:42:29.183217Z","shell.execute_reply.started":"2021-09-04T15:42:29.17361Z","shell.execute_reply":"2021-09-04T15:42:29.181978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Baseline\n\nLets use to baseline models to choose the methods that will allow the model to achieve a good performance.\n\n1 - Logistic Regression\n\n2 - XGBoost\n\nAll the tests will be based on a fraction of 20% of all available data","metadata":{}},{"cell_type":"markdown","source":"# Strategy 1\n\n<ul>\n    <li><h3>Impute values with mean</h3></li>\n    <li><h3>Use all features</h3></li>\n</ul>","metadata":{}},{"cell_type":"code","source":"df_subset = df_train.sample(frac=.20, random_state=42)\nx = df_subset.drop(['id', 'claim'], axis=1)\ny = df_subset['claim']\n\nx_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size = 0.2, random_state = 42)\n\nprint(\"Using 80% of data for training and 20% for testing the baseline models\")\nprint('x_train', x_train.shape, 'y_train', y_train.shape)\nprint('x_valid', x_valid.shape, 'y_valid', y_valid.shape)\n\n# Impute and Scale the values\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nx_train = imputer.fit_transform(x_train)\nx_valid = imputer.transform(x_valid)\n\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_valid = scaler.transform(x_valid)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T21:10:47.808912Z","iopub.execute_input":"2021-09-03T21:10:47.809419Z","iopub.status.idle":"2021-09-03T21:10:49.515761Z","shell.execute_reply.started":"2021-09-03T21:10:47.809366Z","shell.execute_reply":"2021-09-03T21:10:49.514629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Logisct Classifier\nmodel = LogisticRegression(random_state=0)\nmodel.fit(x_train, y_train)\nmodel.score(x_valid, y_valid)\nresults = evaluate_metrics(model, x_valid, y_valid)\n# y_pred_prob = model.predict_proba(x_valid)[:, 1]\n# auc_roc = roc_auc_score(y_pred_prob, y_valid)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T21:11:16.538366Z","iopub.execute_input":"2021-09-03T21:11:16.538804Z","iopub.status.idle":"2021-09-03T21:11:17.163467Z","shell.execute_reply.started":"2021-09-03T21:11:16.538764Z","shell.execute_reply":"2021-09-03T21:11:17.162189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(x_valid)\naccuracy_score(y_valid, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T20:35:37.075209Z","iopub.execute_input":"2021-09-03T20:35:37.075575Z","iopub.status.idle":"2021-09-03T20:35:37.098917Z","shell.execute_reply.started":"2021-09-03T20:35:37.075544Z","shell.execute_reply":"2021-09-03T20:35:37.097543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# XGBoost Classifier\nmodel = XGBClassifier(random_state=0, tree_method='gpu_hist', predictor='gpu_predictor', verbosity=0)\nmodel.fit(x_train, y_train)\ny_pred = model.predict(x_valid)\n# accuracy_score(y_valid, y_pred)\nresults = evaluate_metrics(model, x_valid, y_valid)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T20:43:19.213591Z","iopub.execute_input":"2021-09-03T20:43:19.213966Z","iopub.status.idle":"2021-09-03T20:46:20.543615Z","shell.execute_reply.started":"2021-09-03T20:43:19.213936Z","shell.execute_reply":"2021-09-03T20:46:20.542099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# XGBoost Classifier - 10 estimators\nmodel = XGBClassifier(n_estimators=10, random_state=0, tree_method='gpu_hist', predictor='gpu_predictor', verbosity=0)\nmodel.fit(x_train, y_train)\ny_pred = model.predict(x_valid)\nresults = evaluate_metrics(model, x_valid, y_valid)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T20:46:20.545411Z","iopub.execute_input":"2021-09-03T20:46:20.545737Z","iopub.status.idle":"2021-09-03T20:46:40.230717Z","shell.execute_reply.started":"2021-09-03T20:46:20.545706Z","shell.execute_reply":"2021-09-03T20:46:40.229581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Strategy 2\n\n<ul>\n    <li><h3>Impute values with mean</h3></li>\n    <li><h3>Use features whose mutual information is bigger than 0</h3></li>\n</ul>","metadata":{}},{"cell_type":"code","source":"df_subset = df_train.sample(frac=.20, random_state=42)\ndf_subset = df_subset.drop(mi_scores[mi_scores == 0].index, axis=1)\n\nx = df_subset.drop(['id', 'claim'], axis=1)\ny = df_subset['claim']\n\nx_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size = 0.2, random_state = 42)\n\nprint(\"Using 80% of data for training and 20% for testing the baseline models\")\nprint('x_train', x_train.shape, 'y_train', y_train.shape)\nprint('x_valid', x_valid.shape, 'y_valid', y_valid.shape)\n\n# Impute and Scale the values\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nx_train = imputer.fit_transform(x_train)\nx_valid = imputer.transform(x_valid)\n\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_valid = scaler.transform(x_valid)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T20:48:00.832718Z","iopub.execute_input":"2021-09-03T20:48:00.8331Z","iopub.status.idle":"2021-09-03T20:48:02.124869Z","shell.execute_reply.started":"2021-09-03T20:48:00.833069Z","shell.execute_reply":"2021-09-03T20:48:02.123812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Logisct Classifier\nmodel = LogisticRegression(random_state=0)\nmodel.fit(x_train, y_train)\nresults = evaluate_metrics(model, x_valid, y_valid)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T20:48:05.030327Z","iopub.execute_input":"2021-09-03T20:48:05.030741Z","iopub.status.idle":"2021-09-03T20:48:05.369279Z","shell.execute_reply.started":"2021-09-03T20:48:05.030705Z","shell.execute_reply":"2021-09-03T20:48:05.368004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# XGBoost Classifier\nmodel = XGBClassifier(random_state=0, tree_method='gpu_hist', predictor='gpu_predictor', verbosity=0)\nmodel.fit(x_train, y_train)\nresults = evaluate_metrics(model, x_valid, y_valid)\nprint(results)\n\n# y_pred = model.predict(x_valid)\n# predictions = [round(value) for value in y_pred]\n# accuracy_score(y_valid, predictions)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T20:48:35.890732Z","iopub.execute_input":"2021-09-03T20:48:35.891131Z","iopub.status.idle":"2021-09-03T20:50:16.333426Z","shell.execute_reply.started":"2021-09-03T20:48:35.8911Z","shell.execute_reply":"2021-09-03T20:50:16.331608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# XGBoost Classifier - 10 estimators\nmodel = XGBClassifier(n_estimators=10, random_state=0, tree_method='gpu_hist', predictor='gpu_predictor', verbosity=0)\nmodel.fit(x_train, y_train)\ny_pred = model.predict(x_valid)\nresults = evaluate_metrics(model, x_valid, y_valid)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T20:48:10.724428Z","iopub.execute_input":"2021-09-03T20:48:10.7248Z","iopub.status.idle":"2021-09-03T20:48:22.395095Z","shell.execute_reply.started":"2021-09-03T20:48:10.724767Z","shell.execute_reply":"2021-09-03T20:48:22.393919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Strategy 3\n\n<ul>\n    <li><h3>Drop rows with nans</h3></li>\n    <li><h3>Use all features</h3></li>\n</ul>","metadata":{}},{"cell_type":"code","source":"df_subset = df_train.sample(frac=.20, random_state=42)\ndf_subset = df_subset.dropna()\n\nx = df_subset.drop(['id', 'claim'], axis=1)\ny = df_subset['claim']\n\nx_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size = 0.2, random_state = 42)\n\nprint(\"Using 80% of data for training and 20% for testing the baseline models\")\nprint('x_train', x_train.shape, 'y_train', y_train.shape)\nprint('x_valid', x_valid.shape, 'y_valid', y_valid.shape)\n\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_valid = scaler.transform(x_valid)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T20:50:25.386539Z","iopub.execute_input":"2021-09-03T20:50:25.386925Z","iopub.status.idle":"2021-09-03T20:50:26.239878Z","shell.execute_reply.started":"2021-09-03T20:50:25.386892Z","shell.execute_reply":"2021-09-03T20:50:26.23887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Logisct Classifier\nmodel = LogisticRegression(random_state=0)\nmodel.fit(x_train, y_train)\nresults = evaluate_metrics(model, x_valid, y_valid)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T20:50:29.915305Z","iopub.execute_input":"2021-09-03T20:50:29.915707Z","iopub.status.idle":"2021-09-03T20:50:30.124434Z","shell.execute_reply.started":"2021-09-03T20:50:29.915657Z","shell.execute_reply":"2021-09-03T20:50:30.123331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# XGBoost Classifier\nmodel = XGBClassifier(random_state=0, tree_method='gpu_hist', predictor='gpu_predictor', verbosity=0)\nmodel.fit(x_train, y_train)\nresults = evaluate_metrics(model, x_valid, y_valid)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T20:50:42.001207Z","iopub.execute_input":"2021-09-03T20:50:42.001576Z","iopub.status.idle":"2021-09-03T20:51:51.498168Z","shell.execute_reply.started":"2021-09-03T20:50:42.001546Z","shell.execute_reply":"2021-09-03T20:51:51.497218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# XGBoost Classifier - 10 estimators\nmodel = XGBClassifier(n_estimators=10, random_state=0, tree_method='gpu_hist', predictor='gpu_predictor', verbosity=0)\nmodel.fit(x_train, y_train)\nresults = evaluate_metrics(model, x_valid, y_valid)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T20:51:51.502543Z","iopub.execute_input":"2021-09-03T20:51:51.503941Z","iopub.status.idle":"2021-09-03T20:51:58.580144Z","shell.execute_reply.started":"2021-09-03T20:51:51.503893Z","shell.execute_reply":"2021-09-03T20:51:58.579259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Strategy 4\n\n<ul>\n    <li><h3>Drop rows with nans</h3></li>\n    <li><h3>Use features whose mutual information is bigger than 0</li>\n</ul>","metadata":{}},{"cell_type":"code","source":"df_subset = df_train.sample(frac=.20, random_state=42)\ndf_subset = df_subset.drop(mi_scores[mi_scores == 0].index, axis=1)\ndf_subset = df_subset.dropna()\n\nx = df_subset.drop(['id', 'claim'], axis=1)\ny = df_subset['claim']\n\nx_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size = 0.2, random_state = 42)\n\nprint(\"Using 80% of data for training and 20% for testing the baseline models\")\nprint('x_train', x_train.shape, 'y_train', y_train.shape)\nprint('x_valid', x_valid.shape, 'y_valid', y_valid.shape)\n\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_valid = scaler.transform(x_valid)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T20:52:27.113344Z","iopub.execute_input":"2021-09-03T20:52:27.114046Z","iopub.status.idle":"2021-09-03T20:52:27.90369Z","shell.execute_reply.started":"2021-09-03T20:52:27.114007Z","shell.execute_reply":"2021-09-03T20:52:27.902511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Logistic Classifier\nmodel = LogisticRegression(random_state=0)\nmodel.fit(x_train, y_train)\nresults = evaluate_metrics(model, x_valid, y_valid)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T20:52:27.905335Z","iopub.execute_input":"2021-09-03T20:52:27.905695Z","iopub.status.idle":"2021-09-03T20:52:28.064855Z","shell.execute_reply.started":"2021-09-03T20:52:27.905643Z","shell.execute_reply":"2021-09-03T20:52:28.063753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# XGBoost Classifier\nmodel = XGBClassifier(random_state=0, tree_method='gpu_hist', predictor='gpu_predictor', verbosity=0)\nmodel.fit(x_train, y_train)\nresults = evaluate_metrics(model, x_valid, y_valid)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T20:52:28.067021Z","iopub.execute_input":"2021-09-03T20:52:28.067864Z","iopub.status.idle":"2021-09-03T20:53:17.079414Z","shell.execute_reply.started":"2021-09-03T20:52:28.067808Z","shell.execute_reply":"2021-09-03T20:53:17.078335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# XGBoost Classifier\nmodel = XGBClassifier(n_estimators=10, random_state=0, tree_method='gpu_hist', predictor='gpu_predictor', verbosity=0)\nmodel.fit(x_train, y_train)\nresults = evaluate_metrics(model, x_valid, y_valid)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T20:53:17.081373Z","iopub.execute_input":"2021-09-03T20:53:17.082124Z","iopub.status.idle":"2021-09-03T20:53:22.022559Z","shell.execute_reply.started":"2021-09-03T20:53:17.082073Z","shell.execute_reply":"2021-09-03T20:53:22.021533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Strategy 5\n\n<ul>\n    <li><h3>Use strategy 1</h3></li>\n    <li><h3>Create a sintetic feature. Counting the number of nan values. This was as tip from the discussion board</ul>","metadata":{}},{"cell_type":"code","source":"df_subset = df_train.sample(frac=.20, random_state=42)\nx = df_subset.drop(['id', 'claim'], axis=1)\nx[\"nan_count\"] = x.isnull().sum(axis=1)\ny = df_subset['claim']\nx_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size = 0.2, random_state = 42)\n\nprint(\"Using 80% of data for training and 20% for testing the baseline models\")\nprint('x_train', x_train.shape, 'y_train', y_train.shape)\nprint('x_valid', x_valid.shape, 'y_valid', y_valid.shape)\n\n# Impute and Scale the values\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nx_train = imputer.fit_transform(x_train)\nx_valid = imputer.transform(x_valid)\n\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_valid = scaler.transform(x_valid)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T18:27:15.587746Z","iopub.execute_input":"2021-09-04T18:27:15.588247Z","iopub.status.idle":"2021-09-04T18:27:17.418679Z","shell.execute_reply.started":"2021-09-04T18:27:15.588213Z","shell.execute_reply":"2021-09-04T18:27:17.417549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Logistic Classifier\nmodel = LogisticRegression(random_state=0)\nmodel.fit(x_train, y_train)\nresults = evaluate_metrics(model, x_valid, y_valid)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T18:27:42.582351Z","iopub.execute_input":"2021-09-04T18:27:42.582756Z","iopub.status.idle":"2021-09-04T18:27:43.22062Z","shell.execute_reply.started":"2021-09-04T18:27:42.582724Z","shell.execute_reply":"2021-09-04T18:27:43.217449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# XGBoost Classifier\nmodel = XGBClassifier(random_state=0, tree_method='gpu_hist', predictor='gpu_predictor', verbosity=0)\nmodel.fit(x_train, y_train)\nresults = evaluate_metrics(model, x_valid, y_valid)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T18:31:56.134763Z","iopub.execute_input":"2021-09-04T18:31:56.135251Z","iopub.status.idle":"2021-09-04T18:31:57.837592Z","shell.execute_reply.started":"2021-09-04T18:31:56.135217Z","shell.execute_reply":"2021-09-04T18:31:57.83638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# XGBoost Classifier\nmodel = XGBClassifier(n_estimators=10, random_state=0, tree_method='gpu_hist', predictor='gpu_predictor', verbosity=0)\nmodel.fit(x_train, y_train)\nresults = evaluate_metrics(model, x_valid, y_valid)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T18:32:26.826302Z","iopub.execute_input":"2021-09-04T18:32:26.82671Z","iopub.status.idle":"2021-09-04T18:32:27.63658Z","shell.execute_reply.started":"2021-09-04T18:32:26.826677Z","shell.execute_reply":"2021-09-04T18:32:27.635528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Strategy 6\n\n<ul>\n    <li><h3>Use strategy 2</h3></li>\n    <li><h3>Create a sintetic feature. Counting the number of nan values.</ul>","metadata":{}},{"cell_type":"code","source":"df_subset = df_train.sample(frac=.20, random_state=42)\ndf_subset = df_subset.drop(mi_scores[mi_scores == 0].index, axis=1)\n\nx = df_subset.drop(['id', 'claim'], axis=1)\nx[\"nan_count\"] = x.isnull().sum(axis=1)\ny = df_subset['claim']\n\nx_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size = 0.2, random_state = 42)\n\nprint(\"Using 80% of data for training and 20% for testing the baseline models\")\nprint('x_train', x_train.shape, 'y_train', y_train.shape)\nprint('x_valid', x_valid.shape, 'y_valid', y_valid.shape)\n\n# Impute and Scale the values\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nx_train = imputer.fit_transform(x_train)\nx_valid = imputer.transform(x_valid)\n\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_valid = scaler.transform(x_valid)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T19:40:50.582687Z","iopub.execute_input":"2021-09-04T19:40:50.583107Z","iopub.status.idle":"2021-09-04T19:40:51.800349Z","shell.execute_reply.started":"2021-09-04T19:40:50.583073Z","shell.execute_reply":"2021-09-04T19:40:51.799223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Logistic Classifier\nmodel = LogisticRegression(random_state=0)\nmodel.fit(x_train, y_train)\nresults = evaluate_metrics(model, x_valid, y_valid)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T19:40:51.802356Z","iopub.execute_input":"2021-09-04T19:40:51.802867Z","iopub.status.idle":"2021-09-04T19:40:52.199982Z","shell.execute_reply.started":"2021-09-04T19:40:51.802813Z","shell.execute_reply":"2021-09-04T19:40:52.19848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# XGBoost Classifier\nmodel = XGBClassifier(random_state=0, tree_method='gpu_hist', predictor='gpu_predictor', verbosity=0)\nmodel.fit(x_train, y_train)\nresults = evaluate_metrics(model, x_valid, y_valid)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T19:40:52.206223Z","iopub.execute_input":"2021-09-04T19:40:52.209148Z","iopub.status.idle":"2021-09-04T19:40:53.439123Z","shell.execute_reply.started":"2021-09-04T19:40:52.209076Z","shell.execute_reply":"2021-09-04T19:40:53.437569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# XGBoost Classifier\nmodel = XGBClassifier(n_estimators=10, random_state=0, tree_method='gpu_hist', predictor='gpu_predictor', verbosity=0)\nmodel.fit(x_train, y_train)\nresults = evaluate_metrics(model, x_valid, y_valid)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T19:40:53.441191Z","iopub.execute_input":"2021-09-04T19:40:53.44152Z","iopub.status.idle":"2021-09-04T19:40:53.949311Z","shell.execute_reply.started":"2021-09-04T19:40:53.441483Z","shell.execute_reply":"2021-09-04T19:40:53.948246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extreme Gradient Boosting (XGBoost) - Testing different configurations","metadata":{}},{"cell_type":"code","source":"from tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2021-09-04T18:33:29.995403Z","iopub.execute_input":"2021-09-04T18:33:29.995809Z","iopub.status.idle":"2021-09-04T18:33:30.001598Z","shell.execute_reply.started":"2021-09-04T18:33:29.995755Z","shell.execute_reply":"2021-09-04T18:33:30.000291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_subset = df_train.sample(frac=.20, random_state=42)\nx = df_subset.drop(['id', 'claim'], axis=1)\nx[\"nan_count\"] = x.isnull().sum(axis=1)\ny = df_subset['claim']\n\nx_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size = 0.2, random_state = 42)\n\nprint(\"Using 80% of data for training and 20% for testing the baseline models\")\nprint('x_train', x_train.shape, 'y_train', y_train.shape)\nprint('x_valid', x_valid.shape, 'y_valid', y_valid.shape)\n\n# Impute and Scale the values\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nx_train = imputer.fit_transform(x_train)\nx_valid = imputer.transform(x_valid)\n\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_valid = scaler.transform(x_valid)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T18:33:30.387731Z","iopub.execute_input":"2021-09-04T18:33:30.388174Z","iopub.status.idle":"2021-09-04T18:33:32.25928Z","shell.execute_reply.started":"2021-09-04T18:33:30.388143Z","shell.execute_reply":"2021-09-04T18:33:32.257992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-09-04T18:33:58.925399Z","iopub.execute_input":"2021-09-04T18:33:58.925863Z","iopub.status.idle":"2021-09-04T18:33:58.933322Z","shell.execute_reply.started":"2021-09-04T18:33:58.925823Z","shell.execute_reply":"2021-09-04T18:33:58.930021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1 - Testing different number of estimators ","metadata":{}},{"cell_type":"code","source":"def get_models_n_estimators():\n    models = dict()\n    trees = [10, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 1000, 2000, 3000, 4000, 5000, 6000, 7000]\n    for n in trees:\n        models[str(n)] = XGBClassifier(n_estimators=n, tree_method='gpu_hist', predictor='gpu_predictor', verbosity=0)\n    return models","metadata":{"execution":{"iopub.status.busy":"2021-09-04T18:35:44.258162Z","iopub.execute_input":"2021-09-04T18:35:44.25857Z","iopub.status.idle":"2021-09-04T18:35:44.265814Z","shell.execute_reply.started":"2021-09-04T18:35:44.258537Z","shell.execute_reply":"2021-09-04T18:35:44.264037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = get_models_n_estimators()\nresults, names = list(), list()\ni = 0\n\nfor name, model in tqdm(models.items()):\n    model.fit(x_train, y_train, verbose=True)\n    scores = evaluate_metrics(model, x_valid, y_valid)\n    results.append(scores)\n    names.append(name)\n    print(name, 'accuracy: %.3f auc_roc: %.3f' % (results[i]['accuracy'], results[i]['auc_roc_curve']))\n    i += 1","metadata":{"execution":{"iopub.status.busy":"2021-09-04T18:35:45.330311Z","iopub.execute_input":"2021-09-04T18:35:45.3307Z","iopub.status.idle":"2021-09-04T18:40:51.366188Z","shell.execute_reply.started":"2021-09-04T18:35:45.330668Z","shell.execute_reply":"2021-09-04T18:40:51.364947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2 - Testing different max_depth ","metadata":{}},{"cell_type":"code","source":"def get_models_n_depths():\n    models = dict()\n    for i in range(1,20):\n        models[str(i)] = XGBClassifier(max_depth=i, tree_method='gpu_hist', predictor='gpu_predictor', verbosity=0)\n    return models","metadata":{"execution":{"iopub.status.busy":"2021-09-04T18:46:03.625031Z","iopub.execute_input":"2021-09-04T18:46:03.625412Z","iopub.status.idle":"2021-09-04T18:46:03.631079Z","shell.execute_reply.started":"2021-09-04T18:46:03.625369Z","shell.execute_reply":"2021-09-04T18:46:03.629906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = get_models_n_depths()\nresults, names = list(), list()\ni = 0\n\nfor name, model in tqdm(models.items()):\n    model.fit(x_train, y_train, verbose=True)\n    scores = evaluate_metrics(model, x_valid, y_valid)\n    results.append(scores)\n    names.append(name)\n    print(name, 'accuracy: %.3f auc_roc: %.3f' % (results[i]['accuracy'], results[i]['auc_roc_curve']))\n    i += 1","metadata":{"execution":{"iopub.status.busy":"2021-09-04T18:46:04.009168Z","iopub.execute_input":"2021-09-04T18:46:04.009537Z","iopub.status.idle":"2021-09-04T18:50:19.347446Z","shell.execute_reply.started":"2021-09-04T18:46:04.009504Z","shell.execute_reply":"2021-09-04T18:50:19.345881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3 - Testing different subsamples","metadata":{}},{"cell_type":"code","source":"def get_models_subsamples():\n    models = dict()\n    for i in np.arange(0.1, 1.1, 0.1):\n        key = '%.1f' % i\n        models[key] = XGBClassifier(subsample=i,  tree_method='gpu_hist', predictor='gpu_predictor', verbosity=0)\n    return models","metadata":{"execution":{"iopub.status.busy":"2021-09-04T18:51:31.40608Z","iopub.execute_input":"2021-09-04T18:51:31.406522Z","iopub.status.idle":"2021-09-04T18:51:31.414899Z","shell.execute_reply.started":"2021-09-04T18:51:31.406489Z","shell.execute_reply":"2021-09-04T18:51:31.413774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = get_models_subsamples()\nresults, names = list(), list()\ni = 0\n\nfor name, model in tqdm(models.items()):\n    model.fit(x_train, y_train, verbose=True)\n    scores = evaluate_metrics(model, x_valid, y_valid)\n    results.append(scores)\n    names.append(name)\n    print(name, 'accuracy: %.3f auc_roc: %.3f' % (results[i]['accuracy'], results[i]['auc_roc_curve']))\n    i += 1","metadata":{"execution":{"iopub.status.busy":"2021-09-04T18:51:31.582829Z","iopub.execute_input":"2021-09-04T18:51:31.583214Z","iopub.status.idle":"2021-09-04T18:51:48.784352Z","shell.execute_reply.started":"2021-09-04T18:51:31.583184Z","shell.execute_reply":"2021-09-04T18:51:48.78302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4 - Testing different learning rates","metadata":{}},{"cell_type":"code","source":"def get_models_lr():\n    models = dict()\n    rates = [0.0001, 0.001, 0.003, 0.005, 0.01, 0.03, 0.05, 0.1, 0.12, 0.13, 0.3, 0.5, 1.0]\n    for r in rates:\n        key = '%.4f' % r\n        models[key] = XGBClassifier(eta=r, tree_method='gpu_hist', predictor='gpu_predictor', verbosity=0)\n    return models","metadata":{"execution":{"iopub.status.busy":"2021-09-04T18:52:08.945934Z","iopub.execute_input":"2021-09-04T18:52:08.946332Z","iopub.status.idle":"2021-09-04T18:52:08.955043Z","shell.execute_reply.started":"2021-09-04T18:52:08.946299Z","shell.execute_reply":"2021-09-04T18:52:08.95348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = get_models_lr()\nresults, names = list(), list()\ni = 0\n\nfor name, model in tqdm(models.items()):\n    model.fit(x_train, y_train, verbose=True)\n    scores = evaluate_metrics(model, x_valid, y_valid)\n    results.append(scores)\n    names.append(name)\n    print(name, 'accuracy: %.3f auc_roc: %.3f' % (results[i]['accuracy'], results[i]['auc_roc_curve']))\n    i += 1","metadata":{"execution":{"iopub.status.busy":"2021-09-04T18:52:10.17759Z","iopub.execute_input":"2021-09-04T18:52:10.177999Z","iopub.status.idle":"2021-09-04T18:52:33.874299Z","shell.execute_reply.started":"2021-09-04T18:52:10.177965Z","shell.execute_reply":"2021-09-04T18:52:33.87168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5 - Testing different number of features","metadata":{}},{"cell_type":"code","source":"def get_models_nfeatures():\n    models = dict()\n    for i in np.arange(0.1, 1.1, 0.1):\n        key = '%.1f' % i\n        models[key] = XGBClassifier(colsample_bytree=i, tree_method='gpu_hist', predictor='gpu_predictor', verbosity=0)\n    return models","metadata":{"execution":{"iopub.status.busy":"2021-09-04T18:54:08.396133Z","iopub.execute_input":"2021-09-04T18:54:08.396594Z","iopub.status.idle":"2021-09-04T18:54:08.403591Z","shell.execute_reply.started":"2021-09-04T18:54:08.396559Z","shell.execute_reply":"2021-09-04T18:54:08.402162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = get_models_nfeatures()\nresults, names = list(), list()\ni = 0\n\nfor name, model in tqdm(models.items()):\n    model.fit(x_train, y_train, verbose=True)\n    scores = evaluate_metrics(model, x_valid, y_valid)\n    results.append(scores)\n    names.append(name)\n    print(name, 'accuracy: %.3f auc_roc: %.3f' % (results[i]['accuracy'], results[i]['auc_roc_curve']))\n    i += 1","metadata":{"execution":{"iopub.status.busy":"2021-09-04T18:54:08.740024Z","iopub.execute_input":"2021-09-04T18:54:08.74041Z","iopub.status.idle":"2021-09-04T18:54:24.950673Z","shell.execute_reply.started":"2021-09-04T18:54:08.740375Z","shell.execute_reply":"2021-09-04T18:54:24.949446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Grid Search \n\nLets do a Grid search on some of the best parameters obtained above","metadata":{}},{"cell_type":"code","source":"df_subset = df_train.sample(frac=.20, random_state=42)\nx_train = df_subset.drop(['id', 'claim'], axis=1)\ny_train = df_subset['claim']\nx_train[\"nan_count\"] = x_train.isnull().sum(axis=1)\n\nprint(\"Using 80% of data for training and 20% for testing the baseline models\")\nprint('x_train', x_train.shape, 'y_train', y_train.shape)\nprint('x_valid', x_valid.shape, 'y_valid', y_valid.shape)\n\n# Impute and Scale the values\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nx_train = imputer.fit_transform(x_train)\n\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T18:55:22.110044Z","iopub.execute_input":"2021-09-04T18:55:22.110477Z","iopub.status.idle":"2021-09-04T18:55:24.025817Z","shell.execute_reply.started":"2021-09-04T18:55:22.110445Z","shell.execute_reply":"2021-09-04T18:55:24.024614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {'n_estimators' : [10, 50, 100, 150, 200],\n          'max_depth' : [1,2,3],\n          'subsample' : [0.8, 0.9, 1.0],\n          'eta' : [0.12, 0.13],\n          'colsample_bytree' : [0.1, 0.2]\n         }","metadata":{"execution":{"iopub.status.busy":"2021-09-04T18:55:26.581859Z","iopub.execute_input":"2021-09-04T18:55:26.582396Z","iopub.status.idle":"2021-09-04T18:55:26.594564Z","shell.execute_reply.started":"2021-09-04T18:55:26.582348Z","shell.execute_reply":"2021-09-04T18:55:26.593066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics = ['roc_auc']\ngrid_cv = GridSearchCV(XGBClassifier(tree_method='gpu_hist', predictor='gpu_predictor', verbosity=0), param_grid=params, scoring=metrics, verbose=1, refit='roc_auc', return_train_score=False, n_jobs=-1, cv=3)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T19:01:07.068331Z","iopub.execute_input":"2021-09-04T19:01:07.068769Z","iopub.status.idle":"2021-09-04T19:01:07.075463Z","shell.execute_reply.started":"2021-09-04T19:01:07.068734Z","shell.execute_reply":"2021-09-04T19:01:07.074072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = grid_cv.fit(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T19:01:11.068285Z","iopub.execute_input":"2021-09-04T19:01:11.068814Z","iopub.status.idle":"2021-09-04T19:08:07.665021Z","shell.execute_reply.started":"2021-09-04T19:01:11.068748Z","shell.execute_reply":"2021-09-04T19:08:07.663647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_cv.best_params_","metadata":{"execution":{"iopub.status.busy":"2021-09-04T19:08:54.630901Z","iopub.execute_input":"2021-09-04T19:08:54.631311Z","iopub.status.idle":"2021-09-04T19:08:54.639291Z","shell.execute_reply.started":"2021-09-04T19:08:54.631272Z","shell.execute_reply":"2021-09-04T19:08:54.638049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(grid_cv.best_score_)\nprint(grid_cv.best_params_)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T19:09:00.353404Z","iopub.execute_input":"2021-09-04T19:09:00.353883Z","iopub.status.idle":"2021-09-04T19:09:00.364824Z","shell.execute_reply.started":"2021-09-04T19:09:00.353816Z","shell.execute_reply":"2021-09-04T19:09:00.363022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fit model on entire dataset for submission\n\nLets fit the model on full dataset and submit it","metadata":{}},{"cell_type":"code","source":"x_train = df_train.drop(['id', 'claim'], axis=1)\nx_train[\"nan_count\"] = x_train.isnull().sum(axis=1)\ny_train = df_train['claim']\n\nprint(\"Using all data for training and submiting\")\nprint('x_train', x_train.shape, 'y_train', y_train.shape)\nprint('x_valid', x_valid.shape, 'y_valid', y_valid.shape)\n\n# Impute and Scale the values\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nx_train = imputer.fit_transform(x_train)\n\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T19:09:17.047738Z","iopub.execute_input":"2021-09-04T19:09:17.048225Z","iopub.status.idle":"2021-09-04T19:09:25.627024Z","shell.execute_reply.started":"2021-09-04T19:09:17.048191Z","shell.execute_reply":"2021-09-04T19:09:25.625859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = XGBClassifier(n_estimators=250, eta=0.13, max_depth=5, subsample=0.9, colsample_bytree=0.1, tree_method='gpu_hist', predictor='gpu_predictor')\nmodel = XGBClassifier(**grid_cv.best_params_, tree_method='gpu_hist', predictor='gpu_predictor')\nmodel.fit(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T19:09:25.629096Z","iopub.execute_input":"2021-09-04T19:09:25.62956Z","iopub.status.idle":"2021-09-04T19:09:31.413972Z","shell.execute_reply.started":"2021-09-04T19:09:25.629512Z","shell.execute_reply":"2021-09-04T19:09:31.412678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test =  pd.read_csv('/kaggle/input/tabular-playground-series-sep-2021/test.csv')\nx_test = df_test.drop(['id'], axis=1)\nx_test[\"nan_count\"] = x_test.isnull().sum(axis=1)\n\nprint(\"Using test data for predict and submiting\")\nprint('x_test', x_test.shape)\n\n# Impute and Scale the values\nx_test = imputer.transform(x_test)\nx_test = scaler.transform(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T19:09:43.770905Z","iopub.execute_input":"2021-09-04T19:09:43.771313Z","iopub.status.idle":"2021-09-04T19:09:56.387126Z","shell.execute_reply.started":"2021-09-04T19:09:43.771249Z","shell.execute_reply":"2021-09-04T19:09:56.385909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"claim = model.predict(x_test)\nids = df_test['id'].values\nsubmission = pd.DataFrame({'id' : ids, 'claim' : claim})","metadata":{"execution":{"iopub.status.busy":"2021-09-04T19:09:56.389297Z","iopub.execute_input":"2021-09-04T19:09:56.389753Z","iopub.status.idle":"2021-09-04T19:09:57.838339Z","shell.execute_reply.started":"2021-09-04T19:09:56.389708Z","shell.execute_reply":"2021-09-04T19:09:57.837204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-04T19:09:57.84098Z","iopub.execute_input":"2021-09-04T19:09:57.84141Z","iopub.status.idle":"2021-09-04T19:09:57.852867Z","shell.execute_reply.started":"2021-09-04T19:09:57.841368Z","shell.execute_reply":"2021-09-04T19:09:57.85135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T19:10:11.730281Z","iopub.execute_input":"2021-09-04T19:10:11.730695Z","iopub.status.idle":"2021-09-04T19:10:12.694324Z","shell.execute_reply.started":"2021-09-04T19:10:11.730662Z","shell.execute_reply":"2021-09-04T19:10:12.692928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}