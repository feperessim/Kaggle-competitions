# To put my learning of the course Deep Learning A-Z in practice
# I am applying what I've learnt in practice on here.
# This is a simple neural net for classifying cats and dogs.
# The dataset used here can be downloaded at the following address:
# http://files.fast.ai/data/dogscats.zip
# References?
# https://stackoverflow.com/questions/7762948/how-to-convert-an-rgb-image-to-numpy-array
# https://stackoverflow.com/questions/26392336/importing-images-from-a-directory-python
#


import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from os import listdir
from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense

# Set the location of the dataset and read all filenames
dataset_path = "/home/felipe/Documents/Datasets/dogs_cats/train/"

def load_dataset(dataset_path):
    """
    Loads the Dogs/Cats dataset
    
    Arguments: 
    dataset_path -- String with the dataset path

    Return:
    images -- list of images as numpy arrays
    labels -- list of labels as integers 0 dogs / 1 cats
    """
    images = []
    labels = []
    img_height = 32
    img_width = 32
    dataset_filenames = listdir(dataset_path)

    # Sanity check
    #assert len(dataset_filenames) == 25000
    print(len(dataset_filenames), " samples.")
    for img_name in dataset_filenames:
        # Extract the labels
        if img_name.startswith('cat'):
            which_class = 1
        else:
            which_class = 0
        # load image as a 64 x 64 * 3 pixels thus it only requires 1.2 gb of ram
        image = load_img(dataset_path + img_name, target_size=(img_height, img_width))
        image = img_to_array(image)
        images.append(image)
        labels.append(which_class)
    images = np.asarray(images)
    labels = np.asarray(labels)
    return images, labels

def model():
    """
    Simple feedforward ann
    
    Arguments: 


    Return:
    classifier -- Keras Sequential object representing the model
    """
    # Initializing the ANN
    classifier = Sequential()
    # Adding the Input and the first hidden layer
    classifier.add(Dense(output_dim=768, init='uniform', activation='relu', input_dim=3072))

    # adding more hidden layers
    classifier.add(Dense(output_dim=384, init='uniform', activation='relu'))

    # adding the output layer
    classifier.add(Dense(output_dim=1, init='uniform', activation='sigmoid'))

    # Compiling the ann
    classifier.compile(optimizer = 'adam', loss='binary_crossentropy', metrics=['accuracy'])

    return classifier

# Load the images and split the dataset into 75% for trainning and 25% for testing
images, labels = load_dataset(dataset_path)
X_train, X_test, Y_train, Y_test = train_test_split(images, labels, test_size = 0.25, random_state = 0)
# Flatten the trainning and the test set
X_train_flatten = X_train.reshape(X_train.shape[0], -1)
X_test_flatten = X_test.reshape(X_test.shape[0], -1)

# Standardize the dataset
X_train_normalized = X_train_flatten/255.
X_test_normalized = X_test_flatten/255.

# Y_train = Y_train.reshape(1, Y_train.shape[0])
classifier = model()
classifier.fit(X_train_normalized, Y_train, batch_size=128, epochs=100)

y_pred = classifier.predict(X_test_normalized)
y_pred = (y_pred > 0.5)
y_pre = y_pred.astype(int)
mse = ((Y_test - y_pred)**2).mean(axis=0)

plt.subplot(1,1,1)
plt.plot(classifier.history.history['acc'], label='Accuracy')
plt.xlabel('Observations')
plt.ylabel('MSE Score')
           
# Plotting the graphs due to loss and accuracy
plt.subplot(2,1,1)
plt.plot(classifier.history.history['loss'], label='Trainning loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')

plt.subplot(2,1,2)
plt.plot(classifier.history.history['acc'], label='Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')

plt.show()

# Now we load the images from test1's directory
dataset_path = '/home/felipe/Documents/Datasets/dogs_cats/test1/'
images_test, _ = load_dataset(dataset_path)

# Flatten and normalize the images
images_test_flatten = images_test.reshape(images_test.shape[0], -1)
images_test_normalized = images_test_flatten/255.0

ids = []
labels = []
# Extract the id. Kinda redundant part
dataset_filenames = listdir(dataset_path)
for image_name in dataset_filenames:
    ids.append((image_name.split('.'))[0])

Y_test_pred = classifier.predict(images_test_normalized)
Y_test_pred = (Y_test_pred > 0.5)

dataframe_submission = pd.DataFrame()
dataframe_submission['id'] = ids
dataframe_submission['label'] = Y_test_pred.astype(int)
dataframe_submission.to_csv('submission.csv', index=False)


